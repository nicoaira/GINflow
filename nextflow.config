/*
 * nextflow.config – Default pipeline parameters
 */

////////////////////////////////////////////////////////////////////////////////
// Global params block
////////////////////////////////////////////////////////////////////////////////
params {
    // Inputs / metadata
    input                    = null
    queries                  = null
    outdir                   = 'results'
    header                   = true
    split_size               = 1024
    id_column                = 'transcript_id'
    structure_column_name    = 'secondary_structure'
    sequence_column          = null
    keep_cols                = null
    query_column             = 'id'

    // Embedding generation
    node_embeddings_tsv      = null
    ginfinity_model_path     = null
    num_workers              = 4
    inference_batch_size     = 1024
    use_gpu                  = false
    gpu_type                 = 't4'

    // Windowing
    window_size              = 11
    window_stride            = 1
    max_unpaired_fraction    = null

    // FAISS index & querying
    faiss_k                  = 50
    seed_similarity_threshold = 0.7
    index_type               = 'flat_ip'
    faiss_metric             = 'ip'
    faiss_nlist              = 1024
    faiss_pq_m               = 32
    faiss_pq_bits            = 8
    faiss_opq_m              = 64
    faiss_hnsw_m             = 32
    faiss_hnsw_efc           = 200
    faiss_hnsw_efs           = null
    faiss_exact_rescore      = null
    faiss_use_gpu            = false
    faiss_nprobe             = null

    // Seed clustering
    cluster_span             = 80
    cluster_min_seeds        = 2
    cluster_diagonal_tolerance = 12
    cluster_max_diagonal_span  = 96

    // Alignment
    alignment_gamma          = 1.5
    band_width               = 96
    band_buffer              = 32
    band_max_width           = 0
    xdrop                    = 50
    gap_open                 = 12
    gap_extend               = 2
    alignment_padding        = 32
    background_samples       = 10000
    random_seed              = 42
    score_min                = -4
    score_max                = 8
    top_n                    = 50
    calculate_evalue         = true
    evd_samples              = 1000
    plot_scoring_matrices    = false

    // Visualization & Reporting
    enable_drawings          = true
    enable_report            = true
    drawing_backend          = 'rnartistcore'  // Options: 'rnartistcore' (default) or 'r4rna'
}

conda {
    enabled = true
}

////////////////////////////////////////////////////////////////////////////////
// Profiles – can be combined, e.g. `-profile test,gpu,docker,slurm`
////////////////////////////////////////////////////////////////////////////////
profiles {

    /*
     * Ultra-fast smoke test dataset (runs in < ~1-2 min) for agent branches (codex/*).
     * Derived from `test` but with reduced k/top_n and batch sizes for speed.
     */
    smoke {
        params {
            input                       = "${baseDir}/tests/data/test_input.tsv"
            outdir                      = 'smoke_results'
            queries                     = "${baseDir}/tests/data/test_queries.csv"
            split_size                  = 50
            num_workers                 = 1
            inference_batch_size        = 256
            window_size                 = 5
            faiss_k                     = 20
            seed_similarity_threshold   = 0.6
            top_n                       = 5
            background_samples          = 2000
        }
    }

    /*
     * Small test dataset + minimal resources.
     */
    test {
        params {
            input                       = "${baseDir}/tests/data/test_input.tsv"
            outdir                      = 'test_results'
            queries                     = "${baseDir}/tests/data/test_queries.csv"
            split_size                  = 100
            num_workers                 = 2
            inference_batch_size        = 512
            window_size                 = 7
            faiss_k                     = 50
            seed_similarity_threshold   = 0.65
            top_n                       = 10
            background_samples          = 5000
        }
    }

    /*
     * Local monitoring profile with detailed resource tracking
     */
    monitor {
        // Don't override executor - let other profiles handle that
        // Just enable detailed reporting
        params.enable_monitoring = true
    }

    /*
     * Explicit local executor (mostly for clarity when combining profiles).
     */
    local {
        process.executor = 'local'
    }

    /*
     * SLURM cluster executor.
     * Extend with clusterOptions/queue/time limits as needed.
     */
     
    slurm {
        process {
            executor = 'slurm'

            // generic slurm defaults
            cpus     = 2
            time     = '4h'
            
            clusterOptions = { ["--job-name=" + task.process + "_" + task.index] }

            withLabel: 'gpu' {
                clusterOptions = {
                    def gres = params.gpu_type == 'a100' ? 'gpu:a100:1' : 'gpu:t4:1'
                    def qos = params.gpu_type == 'a100' ? 'class_a' : 'viz'
                    def partition = params.gpu_type == 'a100' ? 'short' : 'viz'
                    def opts = [
                        "--gres=${gres}".toString(),
                        "--job-name=${task.process}_${task.index}".toString(),
                        "--qos=${qos}".toString(),
                        "--partition=${partition}".toString()
                    ]
                    opts
                }
                cpus           = params.gpu_type == 'a100' ? 32 : 8
                memory         = '32 GB'
                time           = params.gpu_type == 'a100' ? '3m' : '12m'
                maxForks       = params.gpu_type == 'a100' ? 24 : 2
            }

            withLabel: 'medium_memory' {
                cpus           = 4
                memory         = '64 GB'
                time           = '30m'

                errorStrategy  = 'retry'
                maxRetries     = 2
                memory         = { 16 * task.attempt + ' GB' }
            }

            withLabel: 'high_memory' {
                cpus           = 4
                time           = '30m'
                errorStrategy  = 'retry'
                maxRetries     = 2
                memory         = { 64 * task.attempt + ' GB' }
            }

            withLabel: 'high_cpu' {
                cpus           = { 16 * task.attempt }
                memory         = '32 GB'
                time           = '30m'
                maxRetries     = 2
            }

            withLabel: 'lightweight' {
                cpus           = 1
                memory         = '8 GB'
                time           = '30m'
            }
        }
    }

    /*
     * Enable GPU support.
     * Sets `params.use_gpu` so other profiles (e.g. `docker`) can react.
     */
    gpu {
        params.use_gpu = true
        params.faiss_use_gpu = true
    }

    /*
     * Software-stack profiles
     * (remain orthogonal; combine freely with the above).
     */
    conda {
        conda.enabled       = true
        docker.enabled      = false
        singularity.enabled = false
        conda.channels      = ['conda-forge', 'bioconda']
    }

    mamba {
        conda.enabled       = true
        conda.useMamba      = true
        docker.enabled      = false
        singularity.enabled = false
    }

    docker {
        docker.enabled      = true
        conda.enabled       = false
        singularity.enabled = false
        // If `gpu` profile is also active, expose all GPUs;
        // otherwise fall back to running as the current UID/GID.
        docker.runOptions = params.use_gpu ? '--gpus all -u $(id -u):$(id -g)' : '-u $(id -u):$(id -g)'
    }

    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        conda.enabled       = false
        docker.enabled      = false
        singularity.runOptions = params.use_gpu ? '--nv' : ''
    }
}

////////////////////////////////////////////////////////////////////////////////
// Execution reports – enable for resource monitoring
////////////////////////////////////////////////////////////////////////////////

trace {
    enabled = true
    file    = "${params.outdir}/reports/trace.tsv"
    overwrite = true
    fields  = 'task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes'
}

report {
    enabled = true
    file    = "${params.outdir}/reports/report.html"
    overwrite = true
}

timeline {
    enabled = true
    file    = "${params.outdir}/reports/timeline.html"
    overwrite = true
}

dag {
    enabled = true
    file    = "${params.outdir}/reports/dag.svg"
    overwrite = true
}

////////////////////////////////////////////////////////////////////////////////
// Pipeline manifest
////////////////////////////////////////////////////////////////////////////////
manifest {
    name       = 'GINflow'
    version    = '0.1.0'
    mainScript = 'main.nf'
}
